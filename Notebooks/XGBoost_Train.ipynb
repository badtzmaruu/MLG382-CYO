{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e78bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real,Categorical, Integer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#Step 1: Import CSVs\n",
    "df_train = pd.read_csv('../Data/train_data.csv', delimiter=\",\")\n",
    "df_test = pd.read_csv('../Data/test_data.csv', delimiter=\",\")\n",
    "\n",
    "#Step 2: Separate features and target\n",
    "X_train = df_train.drop(columns=[\"Rain\"])\n",
    "y_train = df_train['Rain']\n",
    "\n",
    "X_test = df_test.drop(columns=[\"Rain\"])\n",
    "y_test = df_test['Rain']\n",
    "\n",
    "#Step 3: Build a pipeline and train XGBoost Model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('clf', XGBClassifier(eval_metric='mlogloss', random_state=47))\n",
    "])\n",
    "\n",
    "#Step 4: Define hyperparameter search space for Bayesian optimization\n",
    "\n",
    "search_space = {\n",
    "    'clf__max_depth' : Integer(2,8),\n",
    "    'clf__learning_rate' : Real(0.001, 1.0, prior='log-uniform'),\n",
    "    'clf__subsample' : Real(0.5, 1.0),\n",
    "    'clf__colsample_bytree' : Real(0.5, 1.0),\n",
    "    'clf__colsample_bylevel' : Real(0.5, 1.0),\n",
    "    'clf__colsample_bynode' : Real(0.5, 1.0),\n",
    "    'clf__reg_alpha' : Real(0.0, 10.0),\n",
    "    'clf__reg_lambda' : Real(0.0, 10.0),\n",
    "    'clf__gamma' : Real(0.0, 10.0)\n",
    "}\n",
    "\n",
    "#Step 5: Training the XGBoost model\n",
    "opt = BayesSearchCV(pipeline, search_space, cv=3, n_iter=10, scoring='accuracy', random_state=47)\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "#Step 6:Make predictions\n",
    "opt.best_estimator_\n",
    "opt.best_score_\n",
    "opt.score(X_test, y_test)\n",
    "opt.predict(X_test)\n",
    "opt.predict_proba(X_test)\n",
    "\n",
    "predictions = opt.predict(X_test)\n",
    "\n",
    "#Step 7: Evaluation\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"XGBoost Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=label_names, zero_division=0))\n",
    "\n",
    "#Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "labels = sorted(y_test.unique()) \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Step 8: Save the model as pkl file in artifacts\n",
    "with open(\"../Artifacts/xgboost_model.pkl\", \"wb\") as file:\n",
    "   pickle.dump(opt.best_estimator_, file)\n",
    "\n",
    "#Step 9: Save predictions to CSV\n",
    "comp_df = X_test.copy()\n",
    "comp_df[\"Actual_Rain\"] = y_test.values\n",
    "comp_df[\"Predicted_Rain\"] = predictions\n",
    "\n",
    "comp_df.to_csv(\"../Artifacts/xgboost_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
